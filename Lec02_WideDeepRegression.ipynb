{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lec02_WideDeepRegression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leejukyu/Deeplearning/blob/main/Lec02_WideDeepRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPYPTlOubhVd"
      },
      "source": [
        " ## Codes are adapted from SungKim@HKUST"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiH1ryROrPbJ",
        "outputId": "b178f45f-6700-46be-e2cb-25d2dcee8f95"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WR2-JgxorRjC",
        "outputId": "253dfc23-da93-43ce-a6ce-ef8f6b8de770"
      },
      "source": [
        "cd '/content/drive/MyDrive/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2wLF9BOOM2g"
      },
      "source": [
        "## 01. Wide and Deep Model (Diabets_logistic)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GmQTWVFr-qK"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Hg-I4bqsAqW",
        "outputId": "dceee901-28e1-42df-b911-754d5f313361"
      },
      "source": [
        "xy = np.loadtxt('CNNPytorchCodes/data/diabetes.csv', delimiter=',', dtype=np.float32)\n",
        "x_data = Variable(torch.from_numpy(xy[:, 0:-1]))\n",
        "y_data = Variable(torch.from_numpy(xy[:, [-1]]))\n",
        "\n",
        "print(x_data.data.shape)\n",
        "print(y_data.data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([759, 8])\n",
            "torch.Size([759, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nllZAYaWsDNF"
      },
      "source": [
        "class Model(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        In the constructor we instantiate two nn.Linear module\n",
        "        \"\"\"\n",
        "        super(Model, self).__init__()\n",
        "        self.l1 = torch.nn.Linear(8, 6)\n",
        "        self.l2 = torch.nn.Linear(6, 4)\n",
        "        self.l3 = torch.nn.Linear(4, 1)\n",
        "\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        In the forward function we accept a Variable of input data and we must return\n",
        "        a Variable of output data. We can use Modules defined in the constructor as\n",
        "        well as arbitrary operators on Variables.\n",
        "        \"\"\"\n",
        "        out1 = self.sigmoid(self.l1(x))\n",
        "        out2 = self.sigmoid(self.l2(out1))\n",
        "        y_pred = self.sigmoid(self.l3(out2))\n",
        "        return y_pred\n",
        "\n",
        "# our model\n",
        "model = Model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1E9UxaMsFZz",
        "outputId": "38b5d254-c4e3-4eee-b666-d159592d4190"
      },
      "source": [
        "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
        "# in the SGD constructor will contain the learnable parameters of the two\n",
        "# nn.Linear modules which are members of the model.\n",
        "\n",
        "criterion = torch.nn.BCELoss(size_average=True)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5E1JIGHsHic",
        "outputId": "194f5598-c609-4cfd-b468-c79be88de9c4"
      },
      "source": [
        "# Training loop\n",
        "for epoch in range(100):\n",
        "        # Forward pass: Compute predicted y by passing x to the model\n",
        "    y_pred = model(x_data)\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = criterion(y_pred, y_data)\n",
        "    print(epoch, loss.item())\n",
        "\n",
        "    # Zero gradients, perform a backward pass, and update the weights.\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.6850830316543579\n",
            "1 0.6812351942062378\n",
            "2 0.6777719855308533\n",
            "3 0.6746554374694824\n",
            "4 0.6718510389328003\n",
            "5 0.6693276166915894\n",
            "6 0.6670571565628052\n",
            "7 0.6650142073631287\n",
            "8 0.6631759405136108\n",
            "9 0.6615219712257385\n",
            "10 0.6600335240364075\n",
            "11 0.6586939692497253\n",
            "12 0.6574884057044983\n",
            "13 0.6564033031463623\n",
            "14 0.655426561832428\n",
            "15 0.6545471549034119\n",
            "16 0.6537553071975708\n",
            "17 0.6530423760414124\n",
            "18 0.6524002552032471\n",
            "19 0.6518219113349915\n",
            "20 0.6513009071350098\n",
            "21 0.6508314609527588\n",
            "22 0.6504085063934326\n",
            "23 0.650027334690094\n",
            "24 0.6496837735176086\n",
            "25 0.6493740081787109\n",
            "26 0.6490947008132935\n",
            "27 0.6488428711891174\n",
            "28 0.6486157178878784\n",
            "29 0.6484108567237854\n",
            "30 0.6482259035110474\n",
            "31 0.648059070110321\n",
            "32 0.6479084491729736\n",
            "33 0.647772490978241\n",
            "34 0.6476497054100037\n",
            "35 0.6475387811660767\n",
            "36 0.6474385261535645\n",
            "37 0.6473480463027954\n",
            "38 0.6472660899162292\n",
            "39 0.6471920013427734\n",
            "40 0.6471250653266907\n",
            "41 0.6470645070075989\n",
            "42 0.6470096707344055\n",
            "43 0.6469599604606628\n",
            "44 0.6469149589538574\n",
            "45 0.6468741297721863\n",
            "46 0.6468371152877808\n",
            "47 0.6468034982681274\n",
            "48 0.6467729806900024\n",
            "49 0.6467452645301819\n",
            "50 0.6467200517654419\n",
            "51 0.6466971039772034\n",
            "52 0.6466761827468872\n",
            "53 0.6466571092605591\n",
            "54 0.6466396450996399\n",
            "55 0.6466237902641296\n",
            "56 0.6466092467308044\n",
            "57 0.6465958952903748\n",
            "58 0.6465836763381958\n",
            "59 0.6465725302696228\n",
            "60 0.6465621590614319\n",
            "61 0.6465526223182678\n",
            "62 0.6465438604354858\n",
            "63 0.6465356945991516\n",
            "64 0.6465281844139099\n",
            "65 0.6465211510658264\n",
            "66 0.6465147137641907\n",
            "67 0.6465086936950684\n",
            "68 0.6465029716491699\n",
            "69 0.6464976668357849\n",
            "70 0.6464926600456238\n",
            "71 0.6464880108833313\n",
            "72 0.6464836001396179\n",
            "73 0.6464793682098389\n",
            "74 0.6464754343032837\n",
            "75 0.6464716196060181\n",
            "76 0.6464680433273315\n",
            "77 0.6464645862579346\n",
            "78 0.6464612483978271\n",
            "79 0.6464581489562988\n",
            "80 0.6464551091194153\n",
            "81 0.6464520692825317\n",
            "82 0.6464493274688721\n",
            "83 0.6464465260505676\n",
            "84 0.6464438438415527\n",
            "85 0.6464412212371826\n",
            "86 0.646438717842102\n",
            "87 0.6464362144470215\n",
            "88 0.6464337706565857\n",
            "89 0.6464313864707947\n",
            "90 0.6464290618896484\n",
            "91 0.6464267373085022\n",
            "92 0.6464244723320007\n",
            "93 0.646422266960144\n",
            "94 0.6464200615882874\n",
            "95 0.6464179158210754\n",
            "96 0.6464157700538635\n",
            "97 0.6464136242866516\n",
            "98 0.6464114189147949\n",
            "99 0.6464094519615173\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQoffm7IqiAY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuUo2BJEvzDz"
      },
      "source": [
        "## 02. Diabet Classification Using Custom DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T--364TIwLjx"
      },
      "source": [
        "# References\n",
        "# https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/01-basics/pytorch_basics/main.py\n",
        "# http://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sajsCh4RwLmZ"
      },
      "source": [
        "class DiabetesDataset(Dataset):\n",
        "    \"\"\" Diabetes dataset.\"\"\"\n",
        "\n",
        "    # Initialize your data, download, etc.\n",
        "    def __init__(self):\n",
        "        xy = np.loadtxt('./data/diabetes.csv.gz',\n",
        "                        delimiter=',', dtype=np.float32)\n",
        "        self.len = xy.shape[0]\n",
        "        self.x_data = torch.from_numpy(xy[:, 0:-1])\n",
        "        self.y_data = torch.from_numpy(xy[:, [-1]])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCzMnjexwLpW"
      },
      "source": [
        "dataset = DiabetesDataset()\n",
        "train_loader = DataLoader(dataset=dataset,\n",
        "                          batch_size=32,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh16GsZ-wLsJ"
      },
      "source": [
        "class Model(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        In the constructor we instantiate two nn.Linear module\n",
        "        \"\"\"\n",
        "        super(Model, self).__init__()\n",
        "        self.l1 = torch.nn.Linear(8, 6)\n",
        "        self.l2 = torch.nn.Linear(6, 4)\n",
        "        self.l3 = torch.nn.Linear(4, 1)\n",
        "\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        In the forward function we accept a Variable of input data and we must return\n",
        "        a Variable of output data. We can use Modules defined in the constructor as\n",
        "        well as arbitrary operators on Variables.\n",
        "        \"\"\"\n",
        "        out1 = self.sigmoid(self.l1(x))\n",
        "        out2 = self.sigmoid(self.l2(out1))\n",
        "        y_pred = self.sigmoid(self.l3(out2))\n",
        "        return y_pred\n",
        "\n",
        "# our model\n",
        "model = Model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b-Ej1BrwLvJ",
        "outputId": "906e646f-749c-4883-a123-06102b5dfff4"
      },
      "source": [
        "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
        "# in the SGD constructor will contain the learnable parameters of the two\n",
        "# nn.Linear modules which are members of the model.\n",
        "criterion = torch.nn.BCELoss(size_average=True)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38wIbF3ZwLy7",
        "outputId": "9f6d7c65-ac02-4d1c-f859-48f51ee1e915"
      },
      "source": [
        "# Training loop\n",
        "for epoch in range(2):\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "\n",
        "        # wrap them in Variable\n",
        "        inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "        # Forward pass: Compute predicted y by passing x to the model\n",
        "        y_pred = model(inputs)\n",
        "\n",
        "        # Compute and print loss\n",
        "        loss = criterion(y_pred, labels)\n",
        "        print(epoch, i, loss.item())\n",
        "\n",
        "        # Zero gradients, perform a backward pass, and update the weights.\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0 0.6928312182426453\n",
            "0 1 0.6921122074127197\n",
            "0 2 0.6880536079406738\n",
            "0 3 0.6801295280456543\n",
            "0 4 0.6746836304664612\n",
            "0 5 0.68610018491745\n",
            "0 6 0.6735557913780212\n",
            "0 7 0.6752679347991943\n",
            "0 8 0.6570809483528137\n",
            "0 9 0.6714505553245544\n",
            "0 10 0.6776877641677856\n",
            "0 11 0.6772294044494629\n",
            "0 12 0.6846486926078796\n",
            "0 13 0.6462717652320862\n",
            "0 14 0.6157056093215942\n",
            "0 15 0.6139795184135437\n",
            "0 16 0.6406874656677246\n",
            "0 17 0.627046525478363\n",
            "0 18 0.6877992153167725\n",
            "0 19 0.612067461013794\n",
            "0 20 0.7020623087882996\n",
            "0 21 0.6881701350212097\n",
            "0 22 0.611191987991333\n",
            "0 23 0.6691051721572876\n",
            "1 0 0.6891078352928162\n",
            "1 1 0.6754580736160278\n",
            "1 2 0.6482507586479187\n",
            "1 3 0.6756840348243713\n",
            "1 4 0.647898256778717\n",
            "1 5 0.6615686416625977\n",
            "1 6 0.6612523794174194\n",
            "1 7 0.6472554802894592\n",
            "1 8 0.704450786113739\n",
            "1 9 0.5918007493019104\n",
            "1 10 0.6461097002029419\n",
            "1 11 0.5851393938064575\n",
            "1 12 0.6446921229362488\n",
            "1 13 0.6936346888542175\n",
            "1 14 0.5804551243782043\n",
            "1 15 0.694953441619873\n",
            "1 16 0.5776549577713013\n",
            "1 17 0.6086737513542175\n",
            "1 18 0.6795974969863892\n",
            "1 19 0.6435074210166931\n",
            "1 20 0.5542621612548828\n",
            "1 21 0.5670082569122314\n",
            "1 22 0.781071126461029\n",
            "1 23 0.6714583039283752\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DG4BnLRqiFc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO3PzBL27Awr"
      },
      "source": [
        "## 03. Softmax Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiyulabEqiHs"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYDwlcf_7WVI",
        "outputId": "8cf245a4-8379-45dc-b475-dfbf9d96308c"
      },
      "source": [
        "# Cross entropy example\n",
        "import numpy as np\n",
        "# One hot\n",
        "# 0: 1 0 0\n",
        "# 1: 0 1 0\n",
        "# 2: 0 0 1\n",
        "Y = np.array([1, 0, 0])\n",
        "\n",
        "Y_pred1 = np.array([0.7, 0.2, 0.1])\n",
        "Y_pred2 = np.array([0.1, 0.3, 0.6])\n",
        "print(\"loss1 = \", np.sum(-Y * np.log(Y_pred1)))\n",
        "print(\"loss2 = \", np.sum(-Y * np.log(Y_pred2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss1 =  0.35667494393873245\n",
            "loss2 =  2.3025850929940455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XyK47Zh7btu"
      },
      "source": [
        "# Softmax + CrossEntropy (logSoftmax + NLLLoss)\n",
        "loss = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJgR4jNf7fhx"
      },
      "source": [
        "# target is of size nBatch\n",
        "# each element in target has to have 0 <= value < nClasses (0-2)\n",
        "# Input is class, not one-hot\n",
        "Y = Variable(torch.LongTensor([0]), requires_grad=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAbsi8wX7jtD"
      },
      "source": [
        "# input is of size nBatch x nClasses = 1 x 4\n",
        "# Y_pred are logits (not softmax)\n",
        "Y_pred1 = Variable(torch.Tensor([[2.0, 1.0, 0.1]]))\n",
        "Y_pred2 = Variable(torch.Tensor([[0.5, 2.0, 0.3]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dt_QMCmR7mQH",
        "outputId": "c82a360c-5863-43d5-dbf6-689b759f79f6"
      },
      "source": [
        "l1 = loss(Y_pred1, Y)\n",
        "l2 = loss(Y_pred2, Y)\n",
        "\n",
        "print(\"PyTorch Loss1 = \", l1.data, \"\\nPyTorch Loss2=\", l2.data)\n",
        "\n",
        "print(\"Y_pred1=\", torch.max(Y_pred1.data, 1)[1])\n",
        "print(\"Y_pred2=\", torch.max(Y_pred2.data, 1)[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch Loss1 =  tensor(0.4170) \n",
            "PyTorch Loss2= tensor(1.8406)\n",
            "Y_pred1= tensor([0])\n",
            "Y_pred2= tensor([1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMH4T_b-7pUt"
      },
      "source": [
        "# target is of size nBatch\n",
        "# each element in target has to have 0 <= value < nClasses (0-2)\n",
        "# Input is class, not one-hot\n",
        "Y = Variable(torch.LongTensor([2, 0, 1]), requires_grad=False)\n",
        "\n",
        "# input is of size nBatch x nClasses = 2 x 4\n",
        "# Y_pred are logits (not softmax)\n",
        "Y_pred1 = Variable(torch.Tensor([[0.1, 0.2, 0.9],\n",
        "                                 [1.1, 0.1, 0.2],\n",
        "                                 [0.2, 2.1, 0.1]]))\n",
        "\n",
        "\n",
        "Y_pred2 = Variable(torch.Tensor([[0.8, 0.2, 0.3],\n",
        "                                 [0.2, 0.3, 0.5],\n",
        "                                 [0.2, 0.2, 0.5]]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYzH5rM_7zdW",
        "outputId": "2aa8a469-075d-451e-9f5b-e4521a3beea5"
      },
      "source": [
        "l1 = loss(Y_pred1, Y)\n",
        "l2 = loss(Y_pred2, Y)\n",
        "\n",
        "print(\"Batch Loss1 = \", l1.data, \"\\nBatch Loss2=\", l2.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch Loss1 =  tensor(0.4966) \n",
            "Batch Loss2= tensor(1.2389)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3DiU2h7qiMr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9lD4np79TbV"
      },
      "source": [
        "## 04.Softmax Classifier Using MNIST\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygFt6RQh9Stn"
      },
      "source": [
        "# https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-7I0Hw09ef-"
      },
      "source": [
        "# Training settings\n",
        "batch_size = 64\n",
        "\n",
        "# MNIST Dataset\n",
        "train_dataset = datasets.MNIST(root='./data/',\n",
        "                               train=True,\n",
        "                               transform=transforms.ToTensor(),\n",
        "                               download=True)\n",
        "\n",
        "test_dataset = datasets.MNIST(root='./data/',\n",
        "                              train=False,\n",
        "                              transform=transforms.ToTensor())\n",
        "\n",
        "# Data Loader (Input Pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GExnc789hCo"
      },
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.l1 = nn.Linear(784, 520)\n",
        "        self.l2 = nn.Linear(520, 320)\n",
        "        self.l3 = nn.Linear(320, 240)\n",
        "        self.l4 = nn.Linear(240, 120)\n",
        "        self.l5 = nn.Linear(120, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(batch_size, 784)  # Flatten the data (n, 1, 28, 28)-> (n, 784) == x = x.view(64, -1,2)\n",
        "        x = F.relu(self.l1(x))\n",
        "        x = F.relu(self.l2(x))\n",
        "        x = F.relu(self.l3(x))\n",
        "        x = F.relu(self.l4(x))\n",
        "        return self.l5(x)\n",
        "\n",
        "\n",
        "model = Net()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq_d-tHn9mEQ"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZJH0bac9mGw"
      },
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEycEey69hFB"
      },
      "source": [
        "def test():\n",
        "    model.eval() # gradient를 계산하지 않겠다 -> 계산량을 줄여서 빠르게\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        data, target = Variable(data, volatile=True), Variable(target)\n",
        "        output = model(data)\n",
        "        # sum up batch loss\n",
        "        test_loss += criterion(output, target).item()\n",
        "        # get the index of the max\n",
        "        pred = output.data.max(1, keepdim=True)[1] # output 2차원, 1:dim=1(열방향), [1]: max확률랑 레이블위치가 나오는데 레이블위치 반환\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum() # eq: 같은지(1) 다른지(0), view_as : pred랑 dimension 계산할 수 있도록 맞춰주겠다\n",
        "                                                                  # cpu: print로 찍으려면 무조건 cpu로 가져와야해서 강제로 가져옴\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBkMRjF-9qMg",
        "outputId": "94243fd7-69f3-4476-a291-9fe98dc4c32c"
      },
      "source": [
        "for epoch in range(1, 10):\n",
        "    train(epoch)\n",
        "    test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.306516\n",
            "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.307921\n",
            "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.297262\n",
            "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.294854\n",
            "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.295487\n",
            "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.302616\n",
            "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.298371\n",
            "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.296983\n",
            "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.308605\n",
            "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.300529\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.298345\n",
            "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 2.301335\n",
            "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.291287\n",
            "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 2.301517\n",
            "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 2.299700\n",
            "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 2.301294\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 2.308201\n",
            "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 2.293571\n",
            "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 2.294895\n",
            "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 2.302766\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.296577\n",
            "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 2.294716\n",
            "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 2.286691\n",
            "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 2.289172\n",
            "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 2.288047\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.305552\n",
            "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 2.290384\n",
            "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 2.299470\n",
            "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 2.292542\n",
            "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 2.298141\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.296187\n",
            "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 2.291167\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 2.293445\n",
            "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 2.294585\n",
            "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 2.296000\n",
            "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 2.284810\n",
            "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 2.289592\n",
            "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 2.277344\n",
            "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 2.284404\n",
            "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 2.285909\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.281888\n",
            "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 2.294095\n",
            "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 2.283084\n",
            "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 2.282084\n",
            "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 2.287184\n",
            "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 2.280000\n",
            "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 2.279661\n",
            "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 2.276486\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 2.276731\n",
            "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 2.277380\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.264506\n",
            "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 2.268577\n",
            "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 2.270678\n",
            "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 2.261863\n",
            "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 2.271818\n",
            "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 2.266912\n",
            "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 2.277387\n",
            "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 2.264725\n",
            "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 2.254259\n",
            "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 2.242543\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.255121\n",
            "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 2.245400\n",
            "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 2.244997\n",
            "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 2.235677\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 2.259547\n",
            "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 2.237629\n",
            "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 2.239795\n",
            "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 2.247315\n",
            "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 2.229215\n",
            "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 2.205476\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 2.212166\n",
            "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 2.175549\n",
            "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 2.170199\n",
            "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 2.181024\n",
            "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 2.158092\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 2.192279\n",
            "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 2.143865\n",
            "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 2.152642\n",
            "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 2.132701\n",
            "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 2.092634\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.086822\n",
            "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 2.115361\n",
            "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 2.061742\n",
            "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 1.994745\n",
            "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 2.068248\n",
            "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 1.920441\n",
            "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 1.920108\n",
            "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 1.905156\n",
            "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 1.869476\n",
            "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 1.737700\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 1.624860\n",
            "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 1.764711\n",
            "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 1.693965\n",
            "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 1.588366\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0225, Accuracy: 6280/10000 (63%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.364009\n",
            "Train Epoch: 2 [640/60000 (1%)]\tLoss: 1.294365\n",
            "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 1.357647\n",
            "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 1.216259\n",
            "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 1.218378\n",
            "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 1.090624\n",
            "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 1.186896\n",
            "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.949177\n",
            "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.925847\n",
            "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.980053\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.874449\n",
            "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.798589\n",
            "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.899113\n",
            "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.790320\n",
            "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.976146\n",
            "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.758660\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.558771\n",
            "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.795880\n",
            "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.721403\n",
            "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.747540\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.701962\n",
            "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.648770\n",
            "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.840746\n",
            "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.545524\n",
            "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.722454\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.508097\n",
            "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.833999\n",
            "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.537109\n",
            "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.815767\n",
            "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.585220\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.471112\n",
            "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.589947\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.574930\n",
            "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.625230\n",
            "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.671748\n",
            "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.589203\n",
            "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.784030\n",
            "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.728787\n",
            "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.674692\n",
            "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.613250\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.685561\n",
            "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.598793\n",
            "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.736249\n",
            "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.525224\n",
            "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.586488\n",
            "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.558619\n",
            "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.486815\n",
            "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.609861\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.611609\n",
            "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.528691\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.584086\n",
            "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.460913\n",
            "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.348809\n",
            "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.349269\n",
            "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.604317\n",
            "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.649835\n",
            "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.604277\n",
            "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.434485\n",
            "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.613510\n",
            "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.290063\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.526724\n",
            "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.408069\n",
            "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.327973\n",
            "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.552131\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.464008\n",
            "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.520904\n",
            "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.471777\n",
            "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.423317\n",
            "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.347607\n",
            "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.476798\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.415100\n",
            "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.440567\n",
            "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.621126\n",
            "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.340212\n",
            "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.536823\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.358547\n",
            "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.500134\n",
            "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.536890\n",
            "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.416132\n",
            "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.638437\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.519665\n",
            "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.442929\n",
            "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.378937\n",
            "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.544142\n",
            "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.365698\n",
            "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.312495\n",
            "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.421837\n",
            "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.663694\n",
            "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.440694\n",
            "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.456170\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.546875\n",
            "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.379784\n",
            "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.542053\n",
            "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.332695\n",
            "\n",
            "Test set: Average loss: 0.0063, Accuracy: 8835/10000 (88%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.168322\n",
            "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.708046\n",
            "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.234469\n",
            "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.611554\n",
            "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.397160\n",
            "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.336114\n",
            "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.320878\n",
            "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.359399\n",
            "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.529515\n",
            "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.364489\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.434009\n",
            "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.337369\n",
            "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.830368\n",
            "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.717881\n",
            "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.202054\n",
            "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.261253\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.367757\n",
            "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.405094\n",
            "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.274502\n",
            "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.398499\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.487025\n",
            "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.338652\n",
            "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.291468\n",
            "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.209081\n",
            "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.244409\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.323991\n",
            "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.542913\n",
            "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.257617\n",
            "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.374004\n",
            "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.505859\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.265483\n",
            "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.285123\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.274405\n",
            "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.154239\n",
            "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.348437\n",
            "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.496268\n",
            "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.371023\n",
            "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.332012\n",
            "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.370155\n",
            "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.464916\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.261543\n",
            "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.362758\n",
            "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.318595\n",
            "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.139940\n",
            "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.287877\n",
            "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.293989\n",
            "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.329344\n",
            "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.327637\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.159148\n",
            "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.408940\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.341870\n",
            "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.353972\n",
            "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.493713\n",
            "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.401532\n",
            "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.371936\n",
            "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.401862\n",
            "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.263445\n",
            "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.284417\n",
            "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.159737\n",
            "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.278436\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.195223\n",
            "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.371190\n",
            "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.119306\n",
            "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.642268\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.245699\n",
            "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.242056\n",
            "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.264132\n",
            "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.354576\n",
            "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.313263\n",
            "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.164183\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.243969\n",
            "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.324011\n",
            "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.231394\n",
            "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.218486\n",
            "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.349836\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.299298\n",
            "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.211126\n",
            "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.313542\n",
            "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.366650\n",
            "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.439990\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.373418\n",
            "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.401655\n",
            "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.225313\n",
            "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.327416\n",
            "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.179943\n",
            "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.214069\n",
            "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.368199\n",
            "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.142308\n",
            "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.353652\n",
            "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.236185\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.215907\n",
            "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.357630\n",
            "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.324232\n",
            "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.283342\n",
            "\n",
            "Test set: Average loss: 0.0045, Accuracy: 9162/10000 (92%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.275182\n",
            "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.313314\n",
            "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.278642\n",
            "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.143355\n",
            "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.291684\n",
            "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.495407\n",
            "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.305311\n",
            "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.354954\n",
            "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.308264\n",
            "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.126854\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.295794\n",
            "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.258093\n",
            "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.201479\n",
            "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.402963\n",
            "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.359549\n",
            "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.234197\n",
            "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.335940\n",
            "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.438994\n",
            "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.376312\n",
            "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.158318\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.296171\n",
            "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.199191\n",
            "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.296113\n",
            "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.143379\n",
            "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.346446\n",
            "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.363795\n",
            "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.210558\n",
            "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.151583\n",
            "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.156656\n",
            "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.280885\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.314275\n",
            "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.362973\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.270579\n",
            "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.197449\n",
            "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.170460\n",
            "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.282636\n",
            "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.189723\n",
            "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.243484\n",
            "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.334411\n",
            "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.342718\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.270221\n",
            "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.151518\n",
            "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.388864\n",
            "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.227717\n",
            "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.329918\n",
            "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.366685\n",
            "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.120354\n",
            "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.289921\n",
            "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.138192\n",
            "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.301058\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.400844\n",
            "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.208148\n",
            "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.206964\n",
            "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.124261\n",
            "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.237719\n",
            "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.277432\n",
            "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.180632\n",
            "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.186059\n",
            "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.175077\n",
            "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.312034\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.227580\n",
            "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.260487\n",
            "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.234576\n",
            "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.279787\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.450295\n",
            "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.264469\n",
            "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.270003\n",
            "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.253563\n",
            "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.343986\n",
            "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.363317\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.283809\n",
            "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.201055\n",
            "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.199887\n",
            "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.179968\n",
            "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.234205\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.144462\n",
            "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.147579\n",
            "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.253962\n",
            "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.249321\n",
            "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.242688\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.257103\n",
            "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.085529\n",
            "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.258293\n",
            "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.235427\n",
            "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.128519\n",
            "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.315197\n",
            "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.164707\n",
            "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.176324\n",
            "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.083257\n",
            "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.176627\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.323716\n",
            "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.340682\n",
            "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.391871\n",
            "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.204630\n",
            "\n",
            "Test set: Average loss: 0.0034, Accuracy: 9382/10000 (94%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.104500\n",
            "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.163410\n",
            "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.078259\n",
            "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.296655\n",
            "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.209513\n",
            "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.314590\n",
            "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.161009\n",
            "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.169482\n",
            "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.144082\n",
            "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.252334\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.130892\n",
            "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.376019\n",
            "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.182858\n",
            "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.087465\n",
            "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.239829\n",
            "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.191966\n",
            "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.173310\n",
            "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.410301\n",
            "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.490184\n",
            "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.266985\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.284795\n",
            "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.205207\n",
            "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.151064\n",
            "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.280290\n",
            "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.256436\n",
            "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.410123\n",
            "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.122053\n",
            "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.267077\n",
            "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.127650\n",
            "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.306388\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.195285\n",
            "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.141685\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.507965\n",
            "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.146006\n",
            "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.462757\n",
            "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.291847\n",
            "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.271329\n",
            "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.206280\n",
            "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.130541\n",
            "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.393813\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.052799\n",
            "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.225922\n",
            "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.505853\n",
            "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.146262\n",
            "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.175642\n",
            "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.106317\n",
            "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.209291\n",
            "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.128277\n",
            "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.131892\n",
            "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.255554\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.095220\n",
            "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.283941\n",
            "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.216516\n",
            "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.122306\n",
            "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.150170\n",
            "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.263530\n",
            "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.142747\n",
            "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.236529\n",
            "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.139032\n",
            "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.190006\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.177401\n",
            "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.177705\n",
            "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.107737\n",
            "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.173295\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.251027\n",
            "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.137416\n",
            "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.131463\n",
            "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.236841\n",
            "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.275381\n",
            "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.294796\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.182908\n",
            "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.238687\n",
            "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.469326\n",
            "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.376622\n",
            "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.191829\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.053658\n",
            "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.194317\n",
            "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.298146\n",
            "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.072257\n",
            "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.149696\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.427794\n",
            "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.115286\n",
            "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.290052\n",
            "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.171723\n",
            "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.110673\n",
            "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.038205\n",
            "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.065696\n",
            "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.160589\n",
            "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.182991\n",
            "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.371064\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.162613\n",
            "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.139254\n",
            "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.195964\n",
            "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.104874\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy: 9513/10000 (95%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.222832\n",
            "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.170962\n",
            "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.158267\n",
            "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.164594\n",
            "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.223651\n",
            "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.083285\n",
            "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.158290\n",
            "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.089146\n",
            "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.144318\n",
            "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.137056\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.166078\n",
            "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.097956\n",
            "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.245248\n",
            "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.358389\n",
            "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.091049\n",
            "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.134579\n",
            "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.133217\n",
            "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.057493\n",
            "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.173651\n",
            "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.099970\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.079004\n",
            "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.179645\n",
            "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.118740\n",
            "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.284404\n",
            "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.091074\n",
            "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.077939\n",
            "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.158324\n",
            "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.117128\n",
            "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.232234\n",
            "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.178418\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.146438\n",
            "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.160506\n",
            "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.098476\n",
            "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.093212\n",
            "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.099230\n",
            "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.090510\n",
            "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.141281\n",
            "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.503420\n",
            "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.113832\n",
            "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.063672\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.175098\n",
            "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.293953\n",
            "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.237328\n",
            "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.120585\n",
            "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.199770\n",
            "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.103917\n",
            "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.169751\n",
            "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.076046\n",
            "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.168833\n",
            "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.270960\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.042678\n",
            "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.191885\n",
            "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.082526\n",
            "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.171425\n",
            "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.153199\n",
            "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.103304\n",
            "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.061784\n",
            "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.242638\n",
            "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.064811\n",
            "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.117769\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.064969\n",
            "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.203696\n",
            "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.090806\n",
            "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.119496\n",
            "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.185927\n",
            "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.139197\n",
            "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.162330\n",
            "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.116644\n",
            "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.124596\n",
            "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.233181\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.064383\n",
            "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.204789\n",
            "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.258414\n",
            "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.093605\n",
            "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.102516\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.067527\n",
            "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.105890\n",
            "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.204518\n",
            "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.028748\n",
            "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.053133\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.104335\n",
            "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.169330\n",
            "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.107481\n",
            "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.166649\n",
            "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.115814\n",
            "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.151230\n",
            "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.159398\n",
            "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.189390\n",
            "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.182832\n",
            "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.173660\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.131693\n",
            "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.060168\n",
            "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.163916\n",
            "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.180434\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 9554/10000 (96%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.071961\n",
            "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.094828\n",
            "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.139832\n",
            "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.273634\n",
            "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.093291\n",
            "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.143386\n",
            "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.233990\n",
            "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.108718\n",
            "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.310761\n",
            "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.171166\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.182325\n",
            "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.067853\n",
            "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.248062\n",
            "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.280638\n",
            "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.110423\n",
            "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.110578\n",
            "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.132564\n",
            "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.151718\n",
            "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.104760\n",
            "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.081405\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.088965\n",
            "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.204362\n",
            "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.091722\n",
            "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.094342\n",
            "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.083259\n",
            "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.065055\n",
            "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.165626\n",
            "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.088988\n",
            "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.092182\n",
            "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.100501\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.152141\n",
            "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.116699\n",
            "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.230925\n",
            "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.103310\n",
            "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.147315\n",
            "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.119908\n",
            "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.124004\n",
            "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.139803\n",
            "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.082490\n",
            "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.076462\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.075528\n",
            "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.226859\n",
            "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.107111\n",
            "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.052746\n",
            "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.077412\n",
            "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.026260\n",
            "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.068457\n",
            "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.015143\n",
            "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.258798\n",
            "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.088728\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.049594\n",
            "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.075332\n",
            "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.199079\n",
            "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.159790\n",
            "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.151502\n",
            "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.174054\n",
            "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.143795\n",
            "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.120304\n",
            "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.080108\n",
            "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.051011\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.442395\n",
            "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.274718\n",
            "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.099648\n",
            "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.168454\n",
            "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.111794\n",
            "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.279192\n",
            "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.095002\n",
            "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.029689\n",
            "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.196184\n",
            "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.111865\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.171468\n",
            "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.066574\n",
            "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.162164\n",
            "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.180857\n",
            "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.106592\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.062094\n",
            "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.053663\n",
            "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.100739\n",
            "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.117441\n",
            "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.028342\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.086857\n",
            "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.189109\n",
            "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.065356\n",
            "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.203533\n",
            "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.161161\n",
            "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.172425\n",
            "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.141144\n",
            "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.129157\n",
            "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.165577\n",
            "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.079496\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.091127\n",
            "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.112769\n",
            "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.079437\n",
            "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.092962\n",
            "\n",
            "Test set: Average loss: 0.0021, Accuracy: 9602/10000 (96%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.152060\n",
            "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.090681\n",
            "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.158978\n",
            "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.043991\n",
            "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.073326\n",
            "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.061977\n",
            "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.164002\n",
            "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.027215\n",
            "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.028092\n",
            "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.029730\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.163728\n",
            "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.253908\n",
            "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.063759\n",
            "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.102096\n",
            "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.097539\n",
            "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.137880\n",
            "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.099062\n",
            "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.048881\n",
            "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.204245\n",
            "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.077724\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.079772\n",
            "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.061212\n",
            "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.173447\n",
            "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.099781\n",
            "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.179943\n",
            "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.097558\n",
            "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.110792\n",
            "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.200569\n",
            "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.085109\n",
            "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.112361\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.022902\n",
            "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.076918\n",
            "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.065041\n",
            "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.040468\n",
            "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.079062\n",
            "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.115304\n",
            "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.111818\n",
            "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.109490\n",
            "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.071827\n",
            "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.026940\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.044582\n",
            "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.115961\n",
            "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.070645\n",
            "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.044179\n",
            "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.029915\n",
            "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.094498\n",
            "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.078194\n",
            "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.078585\n",
            "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.126666\n",
            "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.053090\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.107720\n",
            "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.158395\n",
            "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.119343\n",
            "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.089967\n",
            "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.209340\n",
            "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.123434\n",
            "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.059966\n",
            "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.062043\n",
            "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.052071\n",
            "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.059134\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.061307\n",
            "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.034628\n",
            "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.123810\n",
            "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.102524\n",
            "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.099651\n",
            "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.063261\n",
            "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.046268\n",
            "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.071583\n",
            "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.163986\n",
            "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.042054\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.018743\n",
            "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.031799\n",
            "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.068893\n",
            "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.090910\n",
            "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.170413\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.197843\n",
            "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.169363\n",
            "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.104298\n",
            "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.104432\n",
            "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.061225\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.235215\n",
            "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.069309\n",
            "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.050421\n",
            "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.083258\n",
            "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.031409\n",
            "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.090961\n",
            "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.077831\n",
            "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.060922\n",
            "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.258420\n",
            "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.110732\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.046463\n",
            "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.044533\n",
            "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.175162\n",
            "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.023977\n",
            "\n",
            "Test set: Average loss: 0.0018, Accuracy: 9666/10000 (97%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.034495\n",
            "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.068992\n",
            "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.054616\n",
            "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.084308\n",
            "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.110724\n",
            "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.050183\n",
            "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.055315\n",
            "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.064139\n",
            "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.126311\n",
            "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.036097\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.039161\n",
            "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.112481\n",
            "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.074271\n",
            "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.130742\n",
            "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.057455\n",
            "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.042392\n",
            "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.147587\n",
            "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.103099\n",
            "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.165334\n",
            "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.084784\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.105838\n",
            "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.155296\n",
            "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.124788\n",
            "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.059106\n",
            "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.091760\n",
            "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.018153\n",
            "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.082270\n",
            "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.143998\n",
            "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.193618\n",
            "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.053054\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.148816\n",
            "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.255980\n",
            "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.041583\n",
            "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.092189\n",
            "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.125921\n",
            "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.150830\n",
            "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.095511\n",
            "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.036775\n",
            "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.077874\n",
            "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.192269\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.101896\n",
            "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.047302\n",
            "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.028317\n",
            "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.083780\n",
            "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.048279\n",
            "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.203243\n",
            "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.030195\n",
            "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.066114\n",
            "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.158730\n",
            "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.117430\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.080366\n",
            "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.131899\n",
            "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.123918\n",
            "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.012822\n",
            "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.080372\n",
            "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.061034\n",
            "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.136793\n",
            "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.169099\n",
            "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.029505\n",
            "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.036210\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.157445\n",
            "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.334915\n",
            "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.067577\n",
            "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.086099\n",
            "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.111223\n",
            "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.155940\n",
            "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.088329\n",
            "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.037033\n",
            "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.072832\n",
            "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.029101\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.044337\n",
            "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.064604\n",
            "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.095488\n",
            "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.128430\n",
            "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.050309\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.119989\n",
            "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.132512\n",
            "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.025435\n",
            "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.039382\n",
            "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.267793\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.104627\n",
            "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.066445\n",
            "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.111999\n",
            "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.162354\n",
            "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.099384\n",
            "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.168395\n",
            "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.101008\n",
            "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.102354\n",
            "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.114640\n",
            "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.014794\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.036069\n",
            "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.049650\n",
            "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.296411\n",
            "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.065309\n",
            "\n",
            "Test set: Average loss: 0.0017, Accuracy: 9668/10000 (97%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd0xQk0z9ekn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCIUtpUlBoE0"
      },
      "source": [
        "## 03. Toy Inception MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge9Fla60BihQ"
      },
      "source": [
        "# https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RSCPF0BBij1"
      },
      "source": [
        "# Training settings\n",
        "batch_size = 64\n",
        "\n",
        "# MNIST Dataset\n",
        "train_dataset = datasets.MNIST(root='./data/',\n",
        "                               train=True,\n",
        "                               transform=transforms.ToTensor(),\n",
        "                               download=True)\n",
        "\n",
        "test_dataset = datasets.MNIST(root='./data/',\n",
        "                              train=False,\n",
        "                              transform=transforms.ToTensor())\n",
        "\n",
        "# Data Loader (Input Pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3UTib-6BylC"
      },
      "source": [
        "class InceptionA(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels):\n",
        "        super(InceptionA, self).__init__()\n",
        "        self.branch1x1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n",
        "\n",
        "        self.branch5x5_1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n",
        "        self.branch5x5_2 = nn.Conv2d(16, 24, kernel_size=5, padding=2)\n",
        "\n",
        "        self.branch3x3dbl_1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n",
        "        self.branch3x3dbl_2 = nn.Conv2d(16, 24, kernel_size=3, padding=1)\n",
        "        self.branch3x3dbl_3 = nn.Conv2d(24, 24, kernel_size=3, padding=1)\n",
        "\n",
        "        self.branch_pool = nn.Conv2d(in_channels, 24, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1x1 = self.branch1x1(x)\n",
        "\n",
        "        branch5x5 = self.branch5x5_1(x)\n",
        "        branch5x5 = self.branch5x5_2(branch5x5)\n",
        "\n",
        "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
        "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
        "        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n",
        "\n",
        "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
        "        branch_pool = self.branch_pool(branch_pool)\n",
        "\n",
        "        outputs = [branch1x1, branch5x5, branch3x3dbl, branch_pool]\n",
        "        return torch.cat(outputs, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhA6o_rVByoc"
      },
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(88, 20, kernel_size=5)\n",
        "\n",
        "        self.incept1 = InceptionA(in_channels=10)\n",
        "        self.incept2 = InceptionA(in_channels=20)\n",
        "\n",
        "        self.mp = nn.MaxPool2d(2)\n",
        "        self.fc = nn.Linear(1408, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        in_size = x.size(0)\n",
        "        x = F.relu(self.mp(self.conv1(x)))\n",
        "        x = self.incept1(x)\n",
        "        x = F.relu(self.mp(self.conv2(x)))\n",
        "        x = self.incept2(x)\n",
        "        x = x.view(in_size, -1)  # flatten the tensor\n",
        "        x = self.fc(x)\n",
        "        return F.log_softmax(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEyjTSb-Byq0"
      },
      "source": [
        "model = Net()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziWS8JL6B8WD"
      },
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWZb8OioB8Yi"
      },
      "source": [
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        data, target = Variable(data, volatile=True), Variable(target)\n",
        "        output = model(data)\n",
        "        # sum up batch loss\n",
        "        test_loss += F.nll_loss(output, target, size_average=False).item()\n",
        "        # get the index of the max log-probability\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhR86b-iCDJ-",
        "outputId": "978b5492-7fe2-4b1c-954c-80b53f08d050"
      },
      "source": [
        "for epoch in range(1, 10):\n",
        "    train(epoch)\n",
        "    test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.298459\n",
            "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.302282\n",
            "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.314808\n",
            "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.313843\n",
            "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.307911\n",
            "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.301989\n",
            "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.292517\n",
            "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.291605\n",
            "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.301653\n",
            "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.293882\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.293476\n",
            "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 2.288318\n",
            "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.307489\n",
            "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 2.282997\n",
            "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 2.300429\n",
            "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 2.278991\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 2.284487\n",
            "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 2.271263\n",
            "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 2.272692\n",
            "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 2.256499\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.247248\n",
            "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 2.219682\n",
            "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 2.218287\n",
            "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 2.199482\n",
            "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 2.072562\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.018283\n",
            "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 1.888470\n",
            "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 1.645551\n",
            "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 1.340695\n",
            "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 1.054764\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.061440\n",
            "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.708808\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.811880\n",
            "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.733036\n",
            "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.503645\n",
            "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.691997\n",
            "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.785598\n",
            "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.522545\n",
            "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.401532\n",
            "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.630583\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.699138\n",
            "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.406982\n",
            "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.309511\n",
            "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.654108\n",
            "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.346521\n",
            "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.403801\n",
            "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.409148\n",
            "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.310570\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.369544\n",
            "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.326941\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.406885\n",
            "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.450345\n",
            "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.314456\n",
            "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.545085\n",
            "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.463935\n",
            "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.441519\n",
            "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.311745\n",
            "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.264772\n",
            "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.340990\n",
            "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.511739\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.370371\n",
            "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.217039\n",
            "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.291192\n",
            "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.268370\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.290411\n",
            "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.244508\n",
            "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.371804\n",
            "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.264199\n",
            "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.092484\n",
            "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.421108\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.278990\n",
            "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.351037\n",
            "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.358358\n",
            "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.330466\n",
            "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.379456\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.236032\n",
            "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.219422\n",
            "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.173511\n",
            "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.307927\n",
            "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.441642\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.190848\n",
            "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.349796\n",
            "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.333977\n",
            "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.300917\n",
            "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.181879\n",
            "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.231879\n",
            "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.267939\n",
            "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.222201\n",
            "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.247269\n",
            "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.274390\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.129102\n",
            "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.319077\n",
            "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.213508\n",
            "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.375303\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.1995, Accuracy: 9402/10000 (94%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.258538\n",
            "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.217049\n",
            "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.169010\n",
            "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.160412\n",
            "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.413642\n",
            "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.295826\n",
            "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.261276\n",
            "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.092610\n",
            "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.242168\n",
            "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.269855\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.191170\n",
            "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.146693\n",
            "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.315070\n",
            "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.197020\n",
            "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.235060\n",
            "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.152280\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.170992\n",
            "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.221109\n",
            "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.164026\n",
            "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.068481\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.227278\n",
            "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.186990\n",
            "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.070408\n",
            "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.054403\n",
            "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.130806\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.146219\n",
            "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.068909\n",
            "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.090442\n",
            "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.097665\n",
            "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.156443\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.238270\n",
            "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.282475\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.075664\n",
            "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.118699\n",
            "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.116094\n",
            "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.295763\n",
            "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.090409\n",
            "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.083746\n",
            "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.155618\n",
            "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.126978\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.150365\n",
            "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.161991\n",
            "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.207581\n",
            "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.198018\n",
            "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.152199\n",
            "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.081553\n",
            "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.158769\n",
            "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.118967\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.286443\n",
            "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.228006\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.193929\n",
            "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.061845\n",
            "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.199084\n",
            "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.054408\n",
            "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.171303\n",
            "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.065156\n",
            "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.119923\n",
            "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.127407\n",
            "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.121178\n",
            "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.109711\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.133274\n",
            "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.272783\n",
            "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.238547\n",
            "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.109010\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.251755\n",
            "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.185380\n",
            "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.152634\n",
            "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.112453\n",
            "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.052718\n",
            "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.064517\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.171271\n",
            "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.049186\n",
            "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.142638\n",
            "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.165405\n",
            "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.190254\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.143566\n",
            "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.082231\n",
            "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.166204\n",
            "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.157046\n",
            "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.123517\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.281554\n",
            "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.097073\n",
            "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.117904\n",
            "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.108541\n",
            "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.087001\n",
            "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.079952\n",
            "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.159783\n",
            "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.030979\n",
            "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.129183\n",
            "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.270887\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.094167\n",
            "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.139767\n",
            "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.175420\n",
            "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.133328\n",
            "\n",
            "Test set: Average loss: 0.0993, Accuracy: 9669/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.170648\n",
            "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.138560\n",
            "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.086426\n",
            "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.211556\n",
            "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.107071\n",
            "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.356113\n",
            "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.062097\n",
            "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.201259\n",
            "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.106286\n",
            "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.107792\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.103604\n",
            "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.199347\n",
            "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.062851\n",
            "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.143251\n",
            "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.084281\n",
            "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.051504\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.026430\n",
            "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.113778\n",
            "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.129343\n",
            "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.098869\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.240272\n",
            "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.037645\n",
            "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.088315\n",
            "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.148072\n",
            "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.127308\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.033290\n",
            "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.089775\n",
            "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.088010\n",
            "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.160561\n",
            "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.144199\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.094785\n",
            "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.140886\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.065263\n",
            "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.060500\n",
            "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.122892\n",
            "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.090418\n",
            "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.095281\n",
            "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.108139\n",
            "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.141379\n",
            "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.069724\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.100991\n",
            "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.034085\n",
            "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.107376\n",
            "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.117907\n",
            "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.036076\n",
            "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.176281\n",
            "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.075367\n",
            "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.123179\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.073479\n",
            "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.123025\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.176704\n",
            "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.020024\n",
            "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.078683\n",
            "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.205316\n",
            "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.099726\n",
            "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.083663\n",
            "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.243602\n",
            "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.151551\n",
            "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.091908\n",
            "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.032886\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.211398\n",
            "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.042125\n",
            "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.051550\n",
            "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.117734\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.027261\n",
            "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.069006\n",
            "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.163546\n",
            "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.101421\n",
            "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.082957\n",
            "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.134693\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.101315\n",
            "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.013861\n",
            "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.140742\n",
            "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.101273\n",
            "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.115871\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.076575\n",
            "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.102614\n",
            "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.056085\n",
            "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.151927\n",
            "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.042757\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.132225\n",
            "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.129050\n",
            "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.069755\n",
            "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.025066\n",
            "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.030698\n",
            "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.128241\n",
            "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.042358\n",
            "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.172904\n",
            "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.202946\n",
            "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.024921\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.034314\n",
            "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.093986\n",
            "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.040812\n",
            "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.275769\n",
            "\n",
            "Test set: Average loss: 0.0781, Accuracy: 9736/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.115700\n",
            "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.159891\n",
            "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.084157\n",
            "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.082409\n",
            "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.114534\n",
            "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.168364\n",
            "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.240476\n",
            "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.051503\n",
            "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.156359\n",
            "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.041403\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.107722\n",
            "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.006747\n",
            "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.160790\n",
            "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.120371\n",
            "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.040461\n",
            "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.071576\n",
            "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.028960\n",
            "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.104348\n",
            "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.081743\n",
            "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.168133\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.080409\n",
            "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.196245\n",
            "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.054231\n",
            "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.080403\n",
            "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.131812\n",
            "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.084675\n",
            "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.094286\n",
            "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.076001\n",
            "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.146797\n",
            "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.032616\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.267053\n",
            "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.022118\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.100542\n",
            "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.241978\n",
            "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.067037\n",
            "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.134078\n",
            "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.151388\n",
            "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.064772\n",
            "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.220536\n",
            "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.142012\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.077108\n",
            "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.059847\n",
            "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.032835\n",
            "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.047832\n",
            "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.035602\n",
            "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.194868\n",
            "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.153751\n",
            "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.032234\n",
            "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.078801\n",
            "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.036398\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.159791\n",
            "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.011107\n",
            "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.067687\n",
            "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.076065\n",
            "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.042721\n",
            "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.012607\n",
            "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.017709\n",
            "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.041356\n",
            "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.044725\n",
            "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.123111\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.065012\n",
            "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.091001\n",
            "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.083161\n",
            "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.093827\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.052253\n",
            "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.121559\n",
            "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.035372\n",
            "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.169356\n",
            "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.102895\n",
            "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.056024\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.159188\n",
            "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.042253\n",
            "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.054006\n",
            "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.078829\n",
            "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.076270\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.052707\n",
            "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.027666\n",
            "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.147481\n",
            "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.102105\n",
            "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.012875\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.106190\n",
            "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.085543\n",
            "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.043952\n",
            "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.189746\n",
            "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.280306\n",
            "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.064627\n",
            "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.056057\n",
            "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.076273\n",
            "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.075768\n",
            "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.107013\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.028665\n",
            "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.021938\n",
            "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.020106\n",
            "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.027112\n",
            "\n",
            "Test set: Average loss: 0.0685, Accuracy: 9784/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.057820\n",
            "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.165115\n",
            "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.037470\n",
            "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.040103\n",
            "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.020856\n",
            "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.048201\n",
            "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.017258\n",
            "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.122846\n",
            "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.114993\n",
            "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.046604\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.322262\n",
            "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.059720\n",
            "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.043759\n",
            "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.024284\n",
            "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.030404\n",
            "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.019994\n",
            "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.110568\n",
            "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.068662\n",
            "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.021905\n",
            "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.054378\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.017373\n",
            "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.156619\n",
            "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.070435\n",
            "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.080143\n",
            "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.038655\n",
            "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.088442\n",
            "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.124663\n",
            "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.047805\n",
            "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.045785\n",
            "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.022912\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.056519\n",
            "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.015752\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.040237\n",
            "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.037050\n",
            "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.046490\n",
            "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.072268\n",
            "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.189665\n",
            "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.012553\n",
            "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.061441\n",
            "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.057284\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.076897\n",
            "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.070235\n",
            "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.032040\n",
            "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.016338\n",
            "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.047734\n",
            "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.014042\n",
            "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.098317\n",
            "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.089698\n",
            "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.241461\n",
            "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.022819\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.078164\n",
            "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.024222\n",
            "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.159130\n",
            "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.095266\n",
            "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.066586\n",
            "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.063557\n",
            "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.021232\n",
            "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.073478\n",
            "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.238276\n",
            "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.019604\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.035445\n",
            "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.089762\n",
            "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.118003\n",
            "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.076584\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.047040\n",
            "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.027693\n",
            "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.026145\n",
            "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.150196\n",
            "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.013808\n",
            "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.173011\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.132879\n",
            "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.054927\n",
            "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.042189\n",
            "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.055055\n",
            "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.031637\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.133017\n",
            "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.055436\n",
            "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.026962\n",
            "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.095666\n",
            "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.016448\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.202858\n",
            "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.060639\n",
            "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.061898\n",
            "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.012719\n",
            "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.040043\n",
            "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.175558\n",
            "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.079903\n",
            "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.012311\n",
            "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.056584\n",
            "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.034126\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.022545\n",
            "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.087674\n",
            "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.378345\n",
            "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.076483\n",
            "\n",
            "Test set: Average loss: 0.0613, Accuracy: 9810/10000 (98%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.164202\n",
            "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.102500\n",
            "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.017067\n",
            "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.047881\n",
            "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.066474\n",
            "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.100150\n",
            "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.183769\n",
            "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.086968\n",
            "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.090347\n",
            "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.084641\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.172917\n",
            "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.145761\n",
            "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.032565\n",
            "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.029026\n",
            "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.042554\n",
            "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.007536\n",
            "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.035639\n",
            "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.146887\n",
            "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.261875\n",
            "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.302498\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.030474\n",
            "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.081499\n",
            "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.019037\n",
            "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.018738\n",
            "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.066420\n",
            "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.038974\n",
            "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.022689\n",
            "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.011074\n",
            "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.128709\n",
            "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.032931\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.032781\n",
            "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.028977\n",
            "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.088064\n",
            "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.074526\n",
            "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.110589\n",
            "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.018449\n",
            "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.078063\n",
            "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.191684\n",
            "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.059489\n",
            "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.040009\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.131528\n",
            "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.067261\n",
            "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.103424\n",
            "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.016754\n",
            "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.101211\n",
            "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.043693\n",
            "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.021884\n",
            "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.086163\n",
            "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.069005\n",
            "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.063699\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.039485\n",
            "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.164711\n",
            "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.015756\n",
            "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.043159\n",
            "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.020043\n",
            "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.024961\n",
            "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.029701\n",
            "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.088259\n",
            "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.018618\n",
            "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.092008\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.042079\n",
            "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.097001\n",
            "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.062448\n",
            "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.064730\n",
            "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.035056\n",
            "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.084534\n",
            "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.143975\n",
            "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.082114\n",
            "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.037576\n",
            "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.012485\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.046472\n",
            "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.210724\n",
            "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.026473\n",
            "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.081646\n",
            "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.074322\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.087720\n",
            "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.070669\n",
            "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.073368\n",
            "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.125411\n",
            "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.080530\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.072058\n",
            "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.081103\n",
            "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.052362\n",
            "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.059940\n",
            "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.024723\n",
            "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.048846\n",
            "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.035134\n",
            "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.034627\n",
            "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.096543\n",
            "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.025712\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.037191\n",
            "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.248727\n",
            "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.055848\n",
            "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.138423\n",
            "\n",
            "Test set: Average loss: 0.0587, Accuracy: 9808/10000 (98%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.101815\n",
            "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.074411\n",
            "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.019099\n",
            "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.027092\n",
            "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.028539\n",
            "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.055592\n",
            "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.079528\n",
            "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.019371\n",
            "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.058734\n",
            "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.075036\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.132473\n",
            "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.043093\n",
            "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.015524\n",
            "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.149736\n",
            "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.201630\n",
            "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.012691\n",
            "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.105585\n",
            "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.062413\n",
            "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.032532\n",
            "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.062707\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.086375\n",
            "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.036326\n",
            "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.125870\n",
            "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.016852\n",
            "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.093513\n",
            "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.091858\n",
            "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.115798\n",
            "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.035243\n",
            "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.224536\n",
            "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.013099\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.013542\n",
            "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.054088\n",
            "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.038775\n",
            "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.031732\n",
            "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.009666\n",
            "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.060248\n",
            "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.036089\n",
            "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.044971\n",
            "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.010181\n",
            "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.128735\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.025630\n",
            "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.088048\n",
            "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.026749\n",
            "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.116285\n",
            "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.152289\n",
            "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.048042\n",
            "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.125752\n",
            "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.029141\n",
            "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.058612\n",
            "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.043716\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.008144\n",
            "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.012084\n",
            "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.005961\n",
            "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.011044\n",
            "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.030894\n",
            "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.172793\n",
            "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.014209\n",
            "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.106960\n",
            "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.017379\n",
            "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.137698\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.120515\n",
            "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.047227\n",
            "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.116516\n",
            "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.135623\n",
            "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.032820\n",
            "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.025315\n",
            "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.011435\n",
            "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.168159\n",
            "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.006209\n",
            "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.194949\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.091509\n",
            "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.019304\n",
            "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.077129\n",
            "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.041079\n",
            "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.081136\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.025167\n",
            "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.082258\n",
            "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.152403\n",
            "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.102351\n",
            "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.034492\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.214477\n",
            "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.083395\n",
            "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.069079\n",
            "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.023391\n",
            "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.008320\n",
            "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.109958\n",
            "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.109407\n",
            "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.010480\n",
            "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.056135\n",
            "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.055276\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.011841\n",
            "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.066476\n",
            "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.083749\n",
            "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.041710\n",
            "\n",
            "Test set: Average loss: 0.0536, Accuracy: 9825/10000 (98%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.078515\n",
            "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.111863\n",
            "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.040148\n",
            "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.034402\n",
            "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.133246\n",
            "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.135164\n",
            "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.044358\n",
            "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.010112\n",
            "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.016614\n",
            "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.011208\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.023697\n",
            "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.034444\n",
            "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.121258\n",
            "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.073405\n",
            "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.020770\n",
            "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.071878\n",
            "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.028991\n",
            "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.060369\n",
            "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.150891\n",
            "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.028589\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.039725\n",
            "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.055759\n",
            "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.035310\n",
            "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.037557\n",
            "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.014804\n",
            "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.163907\n",
            "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.043898\n",
            "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.020074\n",
            "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.064692\n",
            "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.144497\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.067901\n",
            "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.020898\n",
            "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.038207\n",
            "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.026312\n",
            "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.059740\n",
            "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.137592\n",
            "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.033961\n",
            "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.043845\n",
            "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.034381\n",
            "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.045425\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.118250\n",
            "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.079885\n",
            "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.126043\n",
            "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.024484\n",
            "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.029506\n",
            "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.007451\n",
            "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.050132\n",
            "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.047755\n",
            "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.035139\n",
            "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.132446\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.014794\n",
            "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.093465\n",
            "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.074156\n",
            "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.034883\n",
            "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.202094\n",
            "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.085357\n",
            "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.122728\n",
            "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.024437\n",
            "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.011046\n",
            "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.014864\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.022740\n",
            "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.011270\n",
            "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.050693\n",
            "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.043158\n",
            "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.027648\n",
            "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.087456\n",
            "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.017176\n",
            "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.028354\n",
            "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.151460\n",
            "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.045556\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.074245\n",
            "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.045500\n",
            "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.062744\n",
            "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.111121\n",
            "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.005491\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.029665\n",
            "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.119619\n",
            "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.003355\n",
            "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.065596\n",
            "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.084657\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.082757\n",
            "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.053398\n",
            "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.010624\n",
            "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.041479\n",
            "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.083432\n",
            "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.049943\n",
            "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.081266\n",
            "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.005326\n",
            "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.020565\n",
            "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.109341\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.107367\n",
            "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.051295\n",
            "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.016565\n",
            "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.067223\n",
            "\n",
            "Test set: Average loss: 0.0503, Accuracy: 9834/10000 (98%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.103428\n",
            "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.090951\n",
            "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.022459\n",
            "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.101653\n",
            "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.111158\n",
            "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.039981\n",
            "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.072780\n",
            "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.003673\n",
            "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.162489\n",
            "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.058297\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.025645\n",
            "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.048173\n",
            "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.036089\n",
            "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.087676\n",
            "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.054269\n",
            "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.028877\n",
            "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.135258\n",
            "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.037477\n",
            "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.011907\n",
            "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.083992\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.023377\n",
            "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.028539\n",
            "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.036602\n",
            "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.028472\n",
            "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.004973\n",
            "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.013079\n",
            "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.074352\n",
            "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.043865\n",
            "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.051425\n",
            "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.098851\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.011950\n",
            "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.015249\n",
            "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.072036\n",
            "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.005156\n",
            "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.040983\n",
            "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.019498\n",
            "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.005670\n",
            "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.034260\n",
            "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.034565\n",
            "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.060383\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.051681\n",
            "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.013333\n",
            "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.038392\n",
            "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.019739\n",
            "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.076064\n",
            "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.099842\n",
            "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.079739\n",
            "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.007881\n",
            "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.048480\n",
            "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.006277\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.048086\n",
            "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.017888\n",
            "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.007429\n",
            "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.090440\n",
            "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.042577\n",
            "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.010921\n",
            "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.027236\n",
            "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.028643\n",
            "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.131466\n",
            "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.061158\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.040817\n",
            "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.051448\n",
            "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.022467\n",
            "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.021955\n",
            "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.026944\n",
            "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.049203\n",
            "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.020736\n",
            "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.015777\n",
            "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.066339\n",
            "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.008608\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.014566\n",
            "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.022749\n",
            "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.100258\n",
            "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.350156\n",
            "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.009679\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.041543\n",
            "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.125541\n",
            "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.013950\n",
            "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.022698\n",
            "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.034781\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.074877\n",
            "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.085804\n",
            "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.011510\n",
            "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.077823\n",
            "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.045154\n",
            "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.018423\n",
            "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.013129\n",
            "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.083295\n",
            "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.058163\n",
            "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.046699\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.204624\n",
            "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.025385\n",
            "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.033146\n",
            "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.007377\n",
            "\n",
            "Test set: Average loss: 0.0558, Accuracy: 9822/10000 (98%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}